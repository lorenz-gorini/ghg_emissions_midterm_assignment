### Midterm Assignment
The following report analyzes the relation between the ESG indicators, the CO2
emissions and the GDP of 191 countries around the world.

Particularly, this paper is aimed at testing the hypothesis where lower GDP values lead to lower CO2 emissions per capita, but higher CO2 emissions per Watt. Moreover we want to analyze the relationship between other ESG indicators (e.g. gender equity, fair distribution of well-being (???), government expenditure on education, control of corruption, political stability) lead to higher CO2 emissions per capita.

- gender equity
- access to the Internet
- government expenditure on education
- control of corruption
- political stability

```{R}
rm(list = ls())
setwd("C:\\Users\\iutente\\OneDrive\\UCL\\Programming for Social Data Science")

requirements <- c("ggplot2", "tidyr", "dplyr", "readxl", "stringr", "gganimate", "transformr", "reshape")
# install all packages that are not already installed
install.packages(setdiff(requirements, rownames(installed.packages())), repos = "https://cran.r-project.org/")
lapply(requirements, library, character.only = TRUE)
```

```{R}
esg_raw <- read.csv("midterm_assignment\\data\\ESGData.csv")
owid_co2_raw <- read.csv("midterm_assignment\\data\\owid-co2-data.csv") # https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.csv")
# eea_ghg_data <- read_excel("midterm_assignment\\data\\EEA_GHG_proxy_2021.xlsx", sheet="EEA proxy dataset (plus)")
# uk_emissions <- read_excel("midterm_assignment\\data\\Emission_map_UK_NAEIPointsSources_2020.xlsx", sheet = "Data")
```

# ESG data
We have 239 countries. For each country, we have 67 ESG indicators, and for each indicator we have its values for each year from 1960 to 2021. 
The following table shows the list of available ESG indicators in the dataset, divided by sector.
Even though the dataset describes the trend of the ESG indicators over time, I decided not to study these data as time-series because I have not taken a proper course for this yet. So I will select only 2 years out of the years analyzed.
Most of the ESG indicators and Years contain many missing values, so we first analyzed the distribution of NAs in order to select the ESG indicators and Years containing the lowest number of missing values.
Moreover, 
Particularly, the initial idea is to select the more recent year with the lowest number of NAs, and another year from 10-20 years before in order to show a comparison. I will decide which years based on the number of NaNs contained for each year.
So I create another barplot to show how many missing values are associated with each year (considering only the ESG indicators that are most relevant for our analysis).

```{R}
summary(esg_raw)
dim(esg_raw)
names(esg_raw)
head(esg_raw)
esg_country_names <- unique(esg_raw[, "Country.Name"])
length(esg_country_names)
```
# Clean the ESG dataset
1. Drop the ``Indicator.Code`` column because I am only interested in the Indicator
name (and I do not need a standardized code for it) 
```{R}
id_cols_co2 <- c("Country.Name", "Country.Code", "Indicator.Name")
esg_raw <- subset(esg_raw, select = -c(Indicator.Code))
```
2. Fix the names of the Year columns by removing the initial ``X`` character
```{R}
raw_year_cols <- setdiff(colnames(esg_raw), c(id_cols_co2, "X"))
# Modify only the columns defining the year
colnames(esg_raw)[colnames(esg_raw) %in% raw_year_cols] <- str_replace(raw_year_cols, "X", "")
clean_year_cols <- setdiff(colnames(esg_raw), c(id_cols_co2, "X"))
```
3. Analyze the ESG indicators contained in the dataset and select the most relevant ones.
  In the following paragraphs, we will explain the selection criteria into details.

## ESG Indicators
The dataset contains multiple ESG indicators so we decided to select only few of them based on:
   - the number of NAs
   - relevance 
   - non multi-collinearity with the other ESG indicators selected

#### Number of NAs


### Table
Item | Price | # In stock
---|---|---

First, the ESG indicators have been filtered based on their relevance for the
CO2 emissions:

# Economy
- Agricultural land (% of land area)
- Gini index
- GDP growth (annual %)
- Individuals using the Internet (% of population)
- Unemployment, total (% of total labor force) (modeled ILO estimate)
# Governance
- Government Effectiveness: Estimate
- Government expenditure on education, total (% of government expenditure)
- Control of Corruption: Estimate
# Environment
- Adjusted savings: natural resources depletion (% of GNI)
- CO2 emissions (metric tons per capita)
- Droughts, floods, extreme temperatures (% of population, average 1990-2009)
- Heat Index 35 (projected change in days)
- Maximum 5-day Rainfall, 25-year Return Level (projected change in mm)
- Mean Drought Index (projected change, unitless)
- GHG net emissions/removals by LUCF (Mt of CO2 equivalent)
- Mammal species, threatened
- Renewable energy consumption (% of total final energy consumption)
# Human Rights
- Ratio of female to male labor force participation rate (%) (modeled ILO estimate)
- Strength of legal rights index (0=weak to 12=strong)
# Social and Health
- Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)
- Children in employment, total (% of children ages 7-14)
- Mortality rate, under-5 (per 1,000 live births)
- People using safely managed drinking water services (% of population)
- People using safely managed sanitation services (% of population)
- Prevalence of undernourishment (% of population)
- School enrollment, primary (% gross)
- School enrollment, primary and secondary (gross), gender parity index (GPI)


### Summary
```{R}
esg_selected_indicators_raw <- c(
    # Economy
    "Ã„gricultural land (% of land area)",
    "Gini index",
    "GDP growth (annual %)",
    "Individuals using the Internet (% of population)",
    "Unemployment, total (% of total labor force) (modeled ILO estimate)",
    # Governance",
    "Government Effectiveness: Estimate",
    "Government expenditure on education, total (% of government expenditure)",
    "Control of Corruption: Estimate",
    "Political Stability and Absence of Violence/Terrorism: Estimate",
    "Research and development expenditure (% of GDP)",
    # Environment",
    "Adjusted savings: natural resources depletion (% of GNI)",
    "CO2 emissions (metric tons per capita)",
    "Droughts, floods, extreme temperatures (% of population, average 1990-2009)",
    "GHG net emissions/removals by LUCF (Mt of CO2 equivalent)",
    "Heat Index 35 (projected change in days)",
    "Maximum 5-day Rainfall, 25-year Return Level (projected change in mm)",
    "Mean Drought Index (projected change, unitless)",
    "Mammal species, threatened",
    "Renewable energy consumption (% of total final energy consumption)",
    # Human Rights",
    "Ratio of female to male labor force participation rate (%) (modeled ILO estimate)",
    "Strength of legal rights index (0=weak to 12=strong)",
    # Social and Health",
    "Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)",
    "Children in employment, total (% of children ages 7-14)",
    "Mortality rate, under-5 (per 1,000 live births)",
    "People using safely managed drinking water services (% of population)",
    "People using safely managed sanitation services (% of population)",
    "Prevalence of undernourishment (% of population)",
    "School enrollment, primary (% gross)",
    "School enrollment, primary and secondary (gross), gender parity index (GPI)"
)
```

### Analyze the distribution of NAs
Analyze the count and distribution of NAs for each year, in order to
select the most interesting years and ESG indicators with the least number of NAs 
```{R}
esg_clean_fewer_indicators <- esg_raw[esg_raw$Indicator.Name %in% esg_selected_indicators_raw, ]
nan_per_indicator <- esg_clean_fewer_indicators %>%
    group_by(Indicator.Name) %>%
    summarise_all(~ sum(is.na(.)) / length(esg_country_names))

# NOTE: Since melt requires me to create a dataframe, I convert this into dataframe
nan_per_indicator_df <- data.frame(nan_per_indicator)
colnames(nan_per_indicator_df) <- colnames(nan_per_indicator)

# Add a row with the count of NAs for each year but considering all the selected
# ``esg_selected_indicators_raw`` together
total_na_per_year <- summarise_all(esg_clean_fewer_indicators, ~ sum(is.na(.)) / nrow(esg_clean_fewer_indicators))
total_na_per_year[1, 1:4] <- "Sum_over_ESG_indicators"
nan_per_indicator_df[nrow(nan_per_indicator_df) + 1, ] <- total_na_per_year

# Add a column with the count of NAs for each ESG indicator (aggregated over the years)
nan_per_indicator_df[, "Sum_over_Years"] <- rowSums(nan_per_indicator_df[, 5:ncol(nan_per_indicator_df)]) / (ncol(esg_clean_fewer_indicators) - 4)

tail(nan_per_indicator_df)
```
### Plot
```{R}
mean_for_selected_esg <- nan_per_indicator_df[nan_per_indicator_df[, "Indicator.Name"] == "Sum_over_ESG_indicators", "Sum_over_Years"]
nan_per_year_plot <- ggplot(
    data = nan_per_indicator_df, aes(x = Indicator.Name, y = Sum_over_Years)
) +
    geom_bar(stat = "identity", position = position_dodge(), alpha = 0.5) +
    geom_hline(yintercept = mean_for_selected_esg, linetype = "dashed", color = "blue") +
    annotate("text", nan_per_indicator_df[1, "Indicator.Name"], mean_for_selected_esg, hjust = -0.4, vjust = -1, label = "Mean NA ratio") +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 60)) +
    theme(text = element_text(size = 14), aspect.ratio = 5 / 9, axis.text.x = element_text(angle = 90, vjust = 0.1, hjust = 1), legend.position = "right")

ggsave("nan_per_esg_indicator.png", nan_per_year_plot, width = 12, height = 10)
```
### Select 2 years from the time-series
Count NA ratio for few selected ESG indicators in order to identify the year associated with the lowest number of NaNs

```{R}
# Transform the dataset into a columnar format (instead of having one column for each year)
nan_per_year_and_indicator <- melt(nan_per_indicator_df, id = c(id_cols_co2, "X"))

colnames(nan_per_year_and_indicator)[names(nan_per_year_and_indicator) == "variable"] <- "Year"
names(nan_per_year_and_indicator)[names(nan_per_year_and_indicator) == "value"] <- "NA_count"
nan_per_year_and_indicator <- subset(nan_per_year_and_indicator, select = -c(Country.Name, Country.Code, X))

head(nan_per_year_and_indicator)
names(nan_per_year_and_indicator)
dim(nan_per_year_and_indicator)
```

### Barplot with NA count per year
Plot a barplot where:
- ``y`` = `number of NaNs` 
- ``x`` = `Year`
- ``color`` identifies multiple data series corresponding to different ESG indicators

NOTE: The x-axis of the barplot contains years that are not equally distributed. This was the best tradeoff in order to:
i. have a readable plot
ii. highlight the trend where we see that the most recent years contains a lower number of NAs 
iii. based on (ii), we wanted to be able to identify the number of NAs for all the most recent years
```{R}
# min_year <- min(as.numeric(as.character(nan_per_year_and_indicator$Year)))
# Select few ESG indicators and few years to make the plot more readable
selected_years <- c(seq(1960, 2004, by = 10), seq(2005, 2016, by = 3), seq(2017, 2021, by = 1))
nan_per_year_and_select_indicator <- filter(
    nan_per_year_and_indicator,
    nan_per_year_and_indicator$Indicator.Name %in% c(
        # "Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)",
        # "Droughts, floods, extreme temperatures (% of population, average 1990-2009)",
        "Sum_over_ESG_indicators",
        "Income share held by lowest 20%",
        "People using safely managed drinking water services (% of population)",
        "School enrollment, primary (% gross)"
    ) & nan_per_year_and_indicator$Year %in% selected_years,
)
# Set the Year column as character so that it is even;y distributed over the x-axis
nan_per_year_and_select_indicator$Year <- as.character(nan_per_year_and_select_indicator$Year)
nan_per_year_plot <- ggplot(
    data = nan_per_year_and_select_indicator, aes(fill = Indicator.Name, x = Year, y = NA_count)
) +
    geom_bar(stat = "identity", position = position_dodge(), alpha = 0.5) +
    scale_fill_discrete(labels = function(x) str_wrap(x, width = 12)) +
    # scale_x_discrete(breaks = round(selected_years)) +
    theme(legend.position = "right")

ggsave("nan_per_year_and_indicator.png", nan_per_year_plot)
```

We observe that the number of NA varies slightly over the more recent years (2000-2020), but highly varies over the different ESG indicators.
For time reasons, we will not analyze the number of NA further, even though some values could be interpolated based on the values in the previous and following years.
Since I see that in the year 2019 there are fewer NaNs I only select data for that year.
```{R}
SELECTED_YEAR <- "2018"
esg_year_2018_columnar <- esg_clean_fewer_indicators[, c(id_cols_co2, SELECTED_YEAR)]

esg_year_2018 <- pivot_wider(
    esg_year_2018_columnar,
    names_from = "Indicator.Name",
    values_from = SELECTED_YEAR
)
head(esg_year_2018)
```

#### Plot NAs for the selected year
After selecting the year, we plot the NA count for the ESG indicators when considering the selected year 2018.
Another possible approach was to consider the mean of the ESG indicator when considering not only the year 2018, but averaging the value in the year 2018 with the ones from the closest years 2017 and 2019.
On the other hand the plot does not show a significant decrease in the NA count.

```{R}
nan_per_2018_plot <- ggplot(
    data = nan_per_indicator_df, aes(x = Indicator.Name, y = nan_per_indicator_df[, SELECTED_YEAR])
) +
    geom_bar(stat = "identity", position = position_dodge(), alpha = 0.5) +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 60)) +
    theme(
        text = element_text(size = 14),
        aspect.ratio = 5 / 9,
        axis.text.x = element_text(angle = 90, vjust = 0.1, hjust = 1),
        legend.position = "right"
    )

ggsave(paste0("nan_", SELECTED_YEAR, "_per_esg_indicator.png"), nan_per_2018_plot, width = 12, height = 10)
```
```{R}
AVG_YEARS <- c(as.character(as.numeric(SELECTED_YEAR) - 1), SELECTED_YEAR, as.character(as.numeric(SELECTED_YEAR) + 1))
nan_per_2018_plot <- ggplot(
    data = nan_per_indicator_df, aes(x = Indicator.Name, y = rowMeans(nan_per_indicator_df[, AVG_YEARS]))
) +
    geom_bar(stat = "identity", position = position_dodge(), alpha = 0.5) +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 60)) +
    theme(
        text = element_text(size = 14),
        aspect.ratio = 5 / 9,
        axis.text.x = element_text(angle = 90, vjust = 0.1, hjust = 1),
        legend.position = "right"
    )

ggsave("nan_mean_2018_per_esg_indicator.png", nan_per_2018_plot, width = 12, height = 10)
```
Based on the count of NAs for the selected years and the criteria described above,
we selected the following ESG indicators:
```{R}
esg_selected_indicators <- c(
    # Economy
    "Adjusted savings: natural resources depletion (% of GNI)",
    "Individuals using the Internet (% of population)",
    # Governance
    "Government Effectiveness: Estimate",
    "Government expenditure on education, total (% of government expenditure)",
    "Control of Corruption: Estimate",
    # Human Rights
    "Ratio of female to male labor force participation rate (%) (modeled ILO estimate)",
    # Social and Health
    "Mortality rate, under-5 (per 1,000 live births)",
    "School enrollment, primary (% gross)"
)
clean_cols <- c("Country.Code", "Country.Name", esg_selected_indicators)
esg_clean <- esg_year_2018[, clean_cols]
esg_clean <- data.frame(drop_na(esg_clean))
# After conversion to dataframe, the spaces in the names are replaced by "." and
# the names are shortened, so revert this back
colnames(esg_clean) <- clean_cols
head(esg_clean)
```

### Cleaning the CO2 emission dataset
1. Filter on the Year column based on the same selected year 2018, and then drop the ``year`` column:
```{R}
owid_co2_2018 <- owid_co2_raw[owid_co2_raw[, "year"] == 2018, ]
owid_co2_2018 <- subset(owid_co2_2018, select = -c(year))
```
2. Filter the Country codes, based on the ones available in the ESG dataset
```{R}
esg_clean_countries <- unique(esg_clean[["Country.Code"]])
owid_co2_2018_countries <- owid_co2_2018[owid_co2_2018[, "iso_code"] %in% esg_clean_countries, ]
```
3. Compute the ratio of NAs for each covariate
```{R}
owid_co2_id_cols <- c("country", "iso_code")
selected_covariates_co2 <- c("gdp", "co2", "population", "co2_per_capita", "total_ghg", "total_ghg_excluding_lucf", "trade_co2")
owid_co2_few_indicators <- subset(owid_co2_2018_countries, select = c(owid_co2_id_cols, selected_covariates_co2))
# Compute the ratio of NAs for each covariate
total_na_per_column <- summarise_all(owid_co2_few_indicators, ~ sum(is.na(.)) / nrow(owid_co2_few_indicators))
```
According to the results, there are no NAs in the CO2 dataset, expect for 5% in ``gdp`` column and 19% in ``trade_co2``.
For this reason, we decide to use ``co2_per_capita``, ``total_ghg`` and
``total_ghg_excluding_lucf`` as outcome variables. 
4. Based on previous results, we drop ``trade_co2`` column and we drop NAs from ``gdp`` column:
```{R}
owid_co2_few_indicators <- subset(owid_co2_few_indicators, select = -c(trade_co2))
owid_co2_clean <- drop_na(owid_co2_few_indicators, "gdp")
```

### Merging Datasets based on country codes
Out of the original 191 common countries, we only have 95 countries, in common with the second dataset, after filtering out the rows with NAs
```{R}
esg_clean_countries <- unique(esg_clean[["Country.Code"]])
owid_co2_countries <- unique(owid_co2_clean[, "iso_code"])
length(intersect(owid_co2_countries, esg_clean_countries))
```
```{R}
merged_dataset <- merge(owid_co2_clean, esg_clean, by.x = "iso_code", by.y = "Country.Code")
dim(merged_dataset)
```
1. Renaming columns:
```{R}
merged_dataset <- dplyr::rename(merged_dataset, country_name_esg = Country.Name, country_name_co2 = country)
# Convert to dataframe to avoid names with spaces, symbols or unsupported characters
merged_dataset <- data.frame(merged_dataset)
colnames(merged_dataset)
```
2. Compute values per capita:
```{R}
merged_dataset[,"total_ghg_per_capita"] <- merged_dataset[,"total_ghg"] / merged_dataset[,"population"]
merged_dataset[,"total_ghg_excluding_lucf_per_capita"] <- merged_dataset[,"total_ghg_excluding_lucf"] / merged_dataset[,"population"]
```

# Ordinary Linear Regression (OLS)
We used an OLS model according to the formula:
```{Latex}
co2_per_capita ~ gdp + [esg_selected_indicators]
```

### Plotting the distribution of the OLS covariates

```{R}
metadata_cols <- c("iso_code", "country_name_co2", "country_name_esg")
co2_cols <- c(
    "gdp",
    "co2",
    "population",
    "co2_per_capita",
    "total_ghg",
    "total_ghg_excluding_lucf",
    "total_ghg_per_capita",
    "total_ghg_excluding_lucf_per_capita"
)
esg_cols <- setdiff(colnames(merged_dataset), c(metadata_cols,co2_cols))

covariate_sum <- paste(c(esg_cols, "gdp"), sep =" ", collapse=" + ")
co2_ols_formula <- as.formula(paste("co2_per_capita ~ ",covariate_sum,sep = ""))
print(paste0("Computing OLS with formula: ", co2_ols_formula)
model_1 <- lm(formula=co2_ols_formula, data=merged_dataset)
summary(model_1)
```
```{R}

for (indicator_id in 1:length(indicator_cols)) {
    indicator_name <- indicator_cols[indicator_id]
    histo_plot <- ggplot(esg_clean, aes(x = esg_clean[, indicator_name])) +
        theme(text = element_text(size = 20)) +
        geom_histogram(aes(fill = ..count..), bins = 10, color = "black") +
        scale_x_continuous(
            name = indicator_name,
            # breaks = seq(0, max(), 25),
            # limits = c(0, 200)
        ) +
        scale_y_continuous(name = "Count") +
        ggtitle(indicator_name) +
        # scale_fill_gradient("Count", low = "green", high = "red")
        geom_density(alpha = .4, fill = "#FF6666")


    # geom_bar(colour = "black", fill = "white") + # bins=10, stat="count",
    #     geom_density(alpha = .2, fill = "#FF6666")
    filename <- str_replace(paste0("distribution_", indicator_name, ".png"), "%", "")
    print(paste0("Saving to ", filename))
    ggsave(filename, histo_plot)
}
```

```
Plot the relevant variables like: 

```
```{R}
```
